# ğŸŒŸ Non-Invasive Hemoglobin (Hb) Prediction from Fingertip Video

> **AI + Signal Processing + FastAPI Service**

This project builds a complete end-to-end machine learning pipeline that predicts **Hemoglobin (Hb)** levels from fingertip videos combined with basic demographic data.

---

## âœ¨ Features

- ğŸ“¹ **Video â†’ PPG extraction** using optical signal processing
- ğŸ”¬ **Rich PPG feature engineering** (time, frequency, physiological domains)
- ğŸ¤– **ML training pipeline** with Ridge + RandomForest Ensemble
- ğŸ’» **CLI prediction script** for quick analysis
- ğŸŒ **Fully functional FastAPI server** for real-time API-based predictions

---

## ğŸ§  How It Works â€” Overview

```
Fingertip Video (.mp4)
        â†“
Extract GREEN Signal
        â†“
Build PPG Time-Series
        â†“
Rich Feature Set
(time-domain + frequency + HR)
        â†“
Machine Learning Model
(Ridge + RandomForest)
        â†“
   Predicted Hb
```

---

## ğŸ“‚ Project Structure

```
project/
â”‚
â”œâ”€ train_data/              # Labeled training videos (Hb in filename)
â”‚  â”œâ”€ male_25_70_14.6.mp4
â”‚  â”œâ”€ female_23_53_11.3.mp4
â”‚
â”œâ”€ test_data/               # Test videos (no Hb value)
â”‚  â”œâ”€ male_24_45.mp4
â”‚
â”œâ”€ train_data_ppg/          # Auto-generated PPG CSVs
â”‚
â”œâ”€ hb_model.joblib          # Saved model (after training)
â”‚
â”œâ”€ extract_ppg.py           # Video â†’ PPG CSV for training
â”œâ”€ train_model.py           # PPG CSV â†’ ML model
â”œâ”€ predict_hb.py            # Predict Hb for a single video
â”œâ”€ api_app.py               # FastAPI-based prediction API
â””â”€ README.md
```

---

## ğŸ·ï¸ Filename Format Requirements

### Training Videos

Must include true Hb label in filename:

**Format:** `gender_age_weight_hb.mp4`

**Examples:**

- `male_25_70_14.6.mp4`
- `female_23_53_11.3.mp4`

### Testing Videos

**Format:** `gender_age_weight.mp4`

**Examples:**

- `male_24_45.mp4`
- `female_30_62.mp4`

---

## âš™ï¸ Environment Setup (Windows / PowerShell)

### 1. Navigate to Project Directory

```powershell
cd "C:\Path\To\Project"
```

### 2. Create Virtual Environment

```powershell
python -m venv venv
```

### 3. Activate Virtual Environment

```powershell
.\venv\Scripts\activate
```

### 4. Install Dependencies

```powershell
pip install opencv-python numpy pandas scipy scikit-learn joblib fastapi uvicorn[standard]
```

---

## ğŸ”¬ Step 1 â€” Extract PPG from Training Videos

**Script:** `extract_ppg.py`

### What it does:

- Extracts mean **GREEN intensity** from center 50% Ã— 50% ROI
- Builds a time-series signal
- Saves CSV to `train_data_ppg/`

### Run:

```powershell
python extract_ppg.py
```

### Output:

PPG CSVs will appear in:

```
train_data_ppg/
â”œâ”€ male_25_70_14.6.csv
â”œâ”€ female_23_53_11.3.csv
```

---

## ğŸ¤– Step 2 â€” Train the Hb Prediction Model

**Script:** `train_model.py`

### What training does:

1. Loads all CSVs from `train_data_ppg/`
2. Extracts **rich PPG features**:

| Category             | Features                                       |
| -------------------- | ---------------------------------------------- |
| **Statistics**       | mean, std, min, max, p25, p50, p75, range, IQR |
| **Shape**            | skew, kurtosis                                 |
| **Derivative**       | diff_mean, diff_std, diff_abs                  |
| **Autocorrelation**  | lag1, lag2                                     |
| **Frequency domain** | band powers (low/mid/high), power ratios       |
| **Physiological**    | estimated heart rate                           |
| **Signal**           | power, energy                                  |
| **Metadata**         | gender, age, weight                            |

3. Cross-validates **Ridge** (alpha âˆˆ {0.1, 1, 10})
4. Cross-validates **RandomForest** (max_depth âˆˆ {3, 4, 5, 6, None})
5. Builds **Ensemble** = 0.5 Ã— Ridge + 0.5 Ã— RF
6. Saves model to `hb_model.joblib`

### Run:

```powershell
python train_model.py
```

### Output:

You will see printed:

- âœ… CV MAE (realistic error)
- ğŸ“Š Train MAE (debug)
- ğŸ’¾ Saved model path

---

## ğŸ¯ Step 3 â€” Predict Hb for a Single Video (CLI)

**Script:** `predict_hb.py`

### Predict from command line:

```powershell
python predict_hb.py --video test_data\male_24_45.mp4
```

### Output:

```
=========================================
Predicted Hb for test_data\male_24_45.mp4: 13.82 g/dL
=========================================
```

---

## ğŸŒ Step 4 â€” FastAPI HTTP Service

**Script:** `api_app.py`

### Start the API:

```powershell
uvicorn api_app:app --reload --host 0.0.0.0 --port 8000
```

### Open documentation:

ğŸ”— [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ“¡ API Endpoint: `POST /predict`

### Request Type

`multipart/form-data`

### Fields:

| Field    | Type   | Description            |
| -------- | ------ | ---------------------- |
| `gender` | text   | `male` or `female`     |
| `age`    | number | years                  |
| `weight` | number | kg                     |
| `video`  | file   | `.mp4` fingertip video |

### Response:

```json
{
  "hb_pred": 13.7,
  "hr_bpm": 78.2,
  "duration_sec": 14.97,
  "num_samples": 450,
  "gender": "male",
  "age": 24.0,
  "weight": 70.0
}
```

---

## ğŸ–¥ï¸ Calling the API from PowerShell

```powershell
Invoke-RestMethod -Uri "http://127.0.0.1:8000/predict" `
  -Method Post `
  -Form @{
    gender = "male"
    age = "24"
    weight = "70"
    video = Get-Item ".\test_data\male_24_45.mp4"
  }
```

---

## ğŸš€ Quick Commands Summary

### Setup

```powershell
python -m venv venv
.\venv\Scripts\activate
pip install opencv-python numpy pandas scipy scikit-learn joblib fastapi uvicorn[standard]
```

### Extract PPG

```powershell
python extract_ppg.py
```

### Train Model

```powershell
python train_model.py
```

### Predict (CLI)

```powershell
python predict_hb.py --video test_data\sample.mp4
```

### Run API

```powershell
uvicorn api_app:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ“ˆ Accuracy Notes

- **Cross-validation MAE** is your true model accuracy
- More training samples â†’ **significantly improved accuracy**
- Keep videos consistent:
  - âœ… Steady hand
  - âœ… Strong uniform lighting
  - âœ… Full fingertip coverage
  - âœ… Camera not moving

---

## ğŸ“ License

This project is open-source and available for educational and research purposes.

---

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome!

---

## ğŸ“§ Contact

For questions or support, please open an issue in the repository.

---

# How to Run Realtime PPG Scrip

## Webcam

```
python realtime_ppg.py
```

## Or with video file

```
python realtime_ppg.py --video test_data/male_25_70_14.6.mp4 --fs 60
```

**Made with â¤ï¸ for non-invasive health monitoring**
